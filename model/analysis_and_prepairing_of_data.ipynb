{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ab-OLtluMYl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('student-por.csv')"
      ],
      "metadata": {
        "id": "P8yIm75kk7z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "KaRYVf8YG4_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sTve7vjECnYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "df[numeric_columns].hist(bins=15, figsize=(15, 10), layout=(4, 4))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oHphgOmHEYSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('student-por.csv')\n",
        "\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "y25vgTa_C7j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=[np.number])\n",
        "\n",
        "z_scores = (numeric_cols - numeric_cols.mean()) / numeric_cols.std()\n",
        "\n",
        "threshold = 3\n",
        "\n",
        "outliers = (z_scores.abs() > threshold)\n",
        "\n",
        "print(\"Кількість аномалій у кожному числовому стовпці:\")\n",
        "print(outliers.sum())"
      ],
      "metadata": {
        "id": "S-pxW8t0TQ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('G3', axis=1)\n",
        "y = df['G3']\n",
        "\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "\n",
        "X_filtered = X[~y.isin([1, 5, 19, 6])]\n",
        "y_filtered = y[~y.isin([1, 5, 19, 6])]\n",
        "\n",
        "print(Counter(y_filtered))\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "X_res, y_res = smote.fit_resample(X_filtered, y_filtered)\n",
        "\n",
        "print('Resampled dataset shape %s' % Counter(y_res))\n",
        "\n",
        "resampled_df = pd.DataFrame(X_res, columns=X.columns)\n",
        "resampled_df['G3'] = y_res\n",
        "\n",
        "resampled_df.to_csv('student-por-extended.csv', index=False)"
      ],
      "metadata": {
        "id": "bqp5SEdTCX0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('student-por-extended.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "zQjorVeVuVhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df['G3'], bins=15, edgecolor='k', alpha=0.7)\n",
        "plt.title('Розподіл цільової змінної G3', fontsize=14)\n",
        "plt.xlabel('Значення G3', fontsize=12)\n",
        "plt.ylabel('Кількість', fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fcDJo5FbQGiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "df[numeric_columns].hist(bins=15, figsize=(15, 10), layout=(4, 4))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sBQI-LskNWjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=[np.number])\n",
        "\n",
        "z_scores = (numeric_cols - numeric_cols.mean()) / numeric_cols.std()\n",
        "\n",
        "threshold = 3\n",
        "\n",
        "outliers = (z_scores.abs() > threshold)\n",
        "\n",
        "print(\"Кількість аномалій у кожному числовому стовпці:\")\n",
        "print(outliers.sum())"
      ],
      "metadata": {
        "id": "MJK_18HzNKup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(22, 16))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title(\"Кореляційна матриця\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-RC6LEFrdmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_sums = correlation_matrix.abs().sum(axis=1)\n",
        "\n",
        "top_features = correlation_sums.sort_values(ascending=False).head(10).index\n",
        "\n",
        "print(\"Топ характеристики за кореляцією:\", top_features)"
      ],
      "metadata": {
        "id": "gVzYTQhaqu-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = ['G1', 'G2', 'G3', 'Medu', 'higher_yes', 'Fedu', 'failures', 'studytime', 'internet_yes']\n",
        "df_selected = df[selected_features]\n",
        "\n",
        "df_selected.to_csv('selected_features_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "xRyjDuZaq0sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('selected_features_dataset.csv')\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "0ZJGd6zQq4CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "P7puzABTqISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "38KZ8_XPrEdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title(\"Кореляційна матриця\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a599AQQbZGMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df[numeric_columns])\n",
        "plt.title('Boxplot для числових змінних')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ajfXNGM-rO3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['G3'])\n",
        "y = df['G3']"
      ],
      "metadata": {
        "id": "JACBZdzEBzzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X.select_dtypes(exclude=\"object\").columns\n",
        "cat_features = X.select_dtypes(include=\"object\").columns\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "oh_transformer = OneHotEncoder()\n",
        "variance_selector = VarianceThreshold(threshold=0.01)\n",
        "\n",
        "original_columns = X.columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"variance\", variance_selector, num_features),\n",
        "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
        "        (\"StandardScaler\", numeric_transformer, num_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X = preprocessor.fit_transform(X)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "LnaCw4ngvaYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "BOgzvjwhvlr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(true, predicted):\n",
        "    mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2_square = r2_score(true, predicted)\n",
        "    return mae, rmse, r2_square"
      ],
      "metadata": {
        "id": "z7z0VQ4gvsPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_actual_vs_fitted(y_actual, y_pred, model_name):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x=y_actual, y=y_pred, alpha=0.6, color='b', edgecolor=None)\n",
        "    plt.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], 'r--', lw=2)\n",
        "    plt.title(f\"{model_name} - Actual vs Fitted Values\", fontsize=14)\n",
        "    plt.xlabel(\"Actual Values\", fontsize=12)\n",
        "    plt.ylabel(\"Fitted Values\", fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sLz-TjIQnZ2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric_comparison(model_list, mae_list, rmse_list, r2_list):\n",
        "    results_df = pd.DataFrame({\n",
        "        'Model Name': model_list,\n",
        "        'MAE': mae_list,\n",
        "        'RMSE': rmse_list,\n",
        "        'R2': r2_list\n",
        "    })\n",
        "\n",
        "    results_long = results_df.melt(id_vars=\"Model Name\", var_name=\"Metric\", value_name=\"Score\")\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=\"Score\", y=\"Model Name\", hue=\"Metric\", data=results_long, palette=\"coolwarm\")\n",
        "    plt.title(\"Comparison of Metrics for Different Models\", fontsize=14)\n",
        "    plt.xlabel(\"Score\", fontsize=12)\n",
        "    plt.ylabel(\"Model Name\", fontsize=12)\n",
        "    plt.legend(title=\"Metric\", loc='upper right')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DkiI6mX2nZRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso\": Lasso(),\n",
        "    \"Ridge\": Ridge(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "    \"XGBRegressor\": XGBRegressor(),\n",
        "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
        "}\n",
        "\n",
        "model_list = []\n",
        "r2_list = []\n",
        "rmse_list = []\n",
        "mae_list = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    model_list.append(name)\n",
        "\n",
        "    print(\"Model performance for Training set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_train_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_train_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_train_r2:.4f}\")\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print(\"Model performance for Test set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_test_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_test_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_test_r2:.4f}\")\n",
        "\n",
        "    r2_list.append(model_test_r2)\n",
        "    mae_list.append(model_test_mae)\n",
        "    rmse_list.append(model_test_rmse)\n",
        "\n",
        "    print(\"=\"*35)\n",
        "    print('\\n')\n",
        "\n",
        "    plot_actual_vs_fitted(y_test, y_test_pred, name)\n",
        "\n",
        "results_df = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score'])\n",
        "print(results_df.sort_values(by=\"R2_Score\", ascending=False))\n",
        "\n",
        "plot_metric_comparison(model_list, mae_list, rmse_list, r2_list)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EAMR7-_3vukJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeRegressor()\n",
        "}\n",
        "\n",
        "model_list = []\n",
        "r2_list = []\n",
        "rmse_list = []\n",
        "mae_list = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    model_list.append(name)\n",
        "\n",
        "    print(\"Model performance for Training set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_train_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_train_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_train_r2:.4f}\")\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print(\"Model performance for Test set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_test_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_test_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_test_r2:.4f}\")\n",
        "\n",
        "    r2_list.append(model_test_r2)\n",
        "    mae_list.append(model_test_mae)\n",
        "    rmse_list.append(model_test_rmse)\n",
        "\n",
        "    print(\"=\"*35)\n",
        "    print('\\n')\n",
        "\n",
        "results_df = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score'])\n",
        "print(results_df.sort_values(by=\"R2_Score\", ascending=False))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Реальні vs передбачувані значення на тестовій вибірці\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7, edgecolors='k', color='green')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
        "plt.title(\"Real vs Predicted\")\n",
        "plt.xlabel(\"Real Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XevKNHlShC7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Random Forest Regressor\": RandomForestRegressor()\n",
        "}\n",
        "\n",
        "model_list = []\n",
        "r2_list = []\n",
        "rmse_list = []\n",
        "mae_list = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
        "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    model_list.append(name)\n",
        "\n",
        "    print(\"Model performance for Training set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_train_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_train_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_train_r2:.4f}\")\n",
        "\n",
        "    print('----------------------------------')\n",
        "\n",
        "    print(\"Model performance for Test set\")\n",
        "    print(f\"- Root Mean Squared Error: {model_test_rmse:.4f}\")\n",
        "    print(f\"- Mean Absolute Error: {model_test_mae:.4f}\")\n",
        "    print(f\"- R2 Score: {model_test_r2:.4f}\")\n",
        "\n",
        "    r2_list.append(model_test_r2)\n",
        "    mae_list.append(model_test_mae)\n",
        "    rmse_list.append(model_test_rmse)\n",
        "\n",
        "    print(\"=\"*35)\n",
        "    print('\\n')\n",
        "\n",
        "results_df = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score'])\n",
        "print(results_df.sort_values(by=\"R2_Score\", ascending=False))\n",
        "\n",
        "subset = 20\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "x = np.arange(subset)\n",
        "\n",
        "plt.bar(x - 0.2, y_test[:subset], width=0.4, label=\"Real Values\", color=\"blue\")\n",
        "\n",
        "plt.bar(x + 0.2, y_test_pred[:subset], width=0.4, label=\"Predicted Values\", color=\"orange\")\n",
        "\n",
        "plt.title(\"Real vs Predicted\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b25UenFXnIUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}